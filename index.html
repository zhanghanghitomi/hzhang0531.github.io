
<html>

<head>
<title>Hang Zhang</title>
<meta name="author" content="Ping Li">
<meta name="description" content="Personal Homepage">
<meta name="keywords" content="Artificial Intelligence, Machine Learning, Approximate Near Neighor Search, Multi-Armed Bandit, Advertising, Recommendation, Natural Language Processing, Research, Rutgers, Microsoft, LinkedIn">
<meta name="classification" content="Personal Homepage">
</head>

<body bgcolor="f7f7f7" text="black" link="blue" vlink="purple" alink="red">

<h1> <img src="./pic/PingLiPhoto2022.jpeg" width="100"> &nbsp;&nbsp;&nbsp; Ping Li &nbsp;&nbsp;(<img src="./pic/kids2018.JPEG" width="150">   <font size="-1">Alexander, Anderson, Arthur, Adeline</font>)</h1>

Distinguished Engineer, LinkedIn Ads. &nbsp;&nbsp;  <a href="https://www.linkedin.com/in/ping-li-a4624389/">LinkedIn Profile</a><br/><br/>
<a href="mailto:pingli98@gmail.com">pingli98@gmail.com</a> <br/>
700 Bellevue Way NE, Bellevue, WA 98004, USA<br/>
<p>

 <p/><hr>
  <h2> New Publications</h2>
  <ul>
    <b>
    </b>
  <li> Analysis of Error Feedback in Federated Non-Convex Optimization with Biased Compression, <i> Preprint 2023.</i> <a href="./publication/2022FederatedLearningCompression.pdf">pdf</a>         
  <li> Sharper Analysis for Minibatch Stochastic Proximal Point Method: Stability, Smoothness, and Deviation, <i> Journal of Machine Learning Research (JMLR), 2023.</i> <a href="./publication/2023JMLRsharper.pdf">pdf</a>            
  </ul>  
  
<p/><hr>

<h2> Presentations</h2>

<ul>
  <b>
  </b>
  <li>[2022/11] Talk at Stanford on Towards a unified view of trees, neural nets, and kernels at LinkedIn. <a href="./publication/Stanford20221111.pdf">link</a>  
  <li>[2022/09] Talk at LinkedIn on embedding based retrieval (EBR) and approximate near neighbor (ANN) search. <a href="https://www.linkedin.com/feed/update/urn:li:activity:6972533869245865984/">link</a>   
  <li>[2022/08] Talk at Google on boosting and trees <a href="https://www.linkedin.com/feed/update/urn:li:activity:6965026431579951104/">link</a> 

</ul>

<p></p><hr>
  
<h2> Awards</h2>

<ul>
  <b>
  </b>  
  <li> ONR-YIP, Young Investigator Award from the Office of Naval Research
  <li> AFOSR-YIP, Young Investigator Award from the Air Force Office of Scientific Research

</ul>
  
<p></p><hr>
  
<h2> Resources</h2>

<ul>
  <b>
  </b>  
  <li> [2020] Graph-based approximate near neighbor search (GPU and CPU), <a href="https://github.com/pltrees/DaSong">github link</a>      
  <li> [2009-2010] The abc-boost tree package for regression, classificaiton, and ranking, <a href="https://github.com/pltrees/abcboost">github link</a>    
  <li> [2005] The Words dataset used in many papers on hashing and sampling, <a href="https://github.com/pltrees/Smallest-K-Sketch">github link</a>  

</ul>

<p></p><hr>
  
<h2>Publications</h2>
  
  <h4> Advertising (Ads) </h4>
  <ul>
  <li> Media report: A Look at Baidu’s Industrial-Scale GPU Training Architecture. <a href="https://www.nextplatform.com/2021/06/25/a-look-at-baidus-industrial-scale-gpu-training-architecture/">link</a>
  <li> Communication-Efficient TeraByte-Scale Model Training Framework for Online Advertising. <a href="https://arxiv.org/pdf/2201.05500.pdf">pdf</a>    
  <li> Boost CTR Prediction for New Advertisements via Modeling Visual Content. <a href="./publication/BoostCTRVisual2022.pdf">pdf</a>    
  <li> FeatureBox: Feature Engineering on GPUs for Massive-Scale Ads Systems. <a href="./publication/FeatureBox2022.pdf">pdf</a>    
  <li> Decomposing User-APP Graph into Subgraphs for Effective APP and User Embedding Learning. <a href="./publication/UserAppGraph2022.pdf">pdf</a>    
  <li> Tree-based Text-Vision BERT for Video Search in Baidu Video Advertising. <a href="./publication/TreeComboAttention2022.pdf">pdf</a>        
  <li> EGM: Enhanced Graph-based Model for Large-scale Video Advertisement Search, <i> KDD 2022. </i> <a href="https://dl.acm.org/doi/pdf/10.1145/3534678.3539061">pdf</a>        
  <li> Multi-scale Multi-modal Dictionary BERT For Effective Text-image Retrieval in Multimedia Advertising, <i> CIKM 2022.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3511808.3557653">pdf</a>    
  <li> Agile and Accurate CTR Prediction Model Training for Massive-Scale Online Advertising Systems, <i> SIGMOD 2021. </i> <a href="https://dl.acm.org/doi/pdf/10.1145/3448016.3457236">pdf</a>      
  <li> GemNN: Gating-Enhanced Multi-Task Neural Networks with Feature Interaction Learning for CTR Prediction, <i> SIGIR 2021.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3404835.3463116">pdf</a>  
  <li> Heterogeneous Attention Network for Effective and Efficient Cross-modal Retrieval, <i> SIGIR 2021.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3404835.3462924">pdf</a>
  <li> TIRA in Baidu Image Advertising, <i> ICDE 2021.</i> <a href="https://ieeexplore.ieee.org/document/9458762">pdf</a>
  <li> Efficient Learning to Learn a Robust CTR Model for Web-scale Online Sponsored Search Advertising, <i> CIKM 2021.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3459637.3481912">pdf</a>
  <li> Multi-modal Dictionary BERT for Cross-modal Video Search in Baidu Advertising, <i> CIKM 2021.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3459637.3481937">pdf</a>
  <li> MixBERT for Multi-modal Matching in Image Advertising, <i> CIKM 2021.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3459637.3482143">pdf</a>
  <li> Assorted Attention Network for Cross-Lingual Language-to-Vision Retrieval, <i> CIKM 2021.</i> <a href="https://dl.acm.org/doi/10.1145/3459637.3482233">pdf</a>
  <li> Combo-Attention Network for Baidu Video Advertising, <i> KDD 2020.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3394486.3403297">pdf</a>             
  <li> Video Recommendation with Multi-gate Mixture of Experts Soft Actor Critic, <i> SIGIR 2020.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3397271.3401238">pdf</a>              
  <li> Distributed Hierarchical GPU Parameter Server for Massive Scale Deep Learning Ads Systems, <i> MLSys 2020.</i> <a href="https://arxiv.org/pdf/2003.05622.pdf">pdf</a>           
  <li> Sample Optimization For Display Advertising, <i> CIKM 2020.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3340531.3412162">pdf</a>
  <li> AIBox: CTR Prediction Model Training on a Single Node, <i> CIKM 2019.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3357384.3358045">pdf</a>             
  <li> MOBIUS: Towards the Next Generation of Query-Ad Matching in Baidu’s Sponsored Search, <i> KDD 2019.</i> <a href="http://research.baidu.com/Public/uploads/5d12eca098d40.pdf">pdf</a>         
  </ul>

  <h4> Input method editor (IME) </h4>
  <ul> 
  <li> Improved Touch-screen Inputting Using Sequence-level Prediction Generation, <i> WWW 2020. </i> <a href="https://dl.acm.org/doi/pdf/10.1145/3366423.3380080">pdf</a>    
  <li> FastInput: Improving Input Efficiency on Mobile Devices, <i> CIKM 2018. </i> <a href="https://dl.acm.org/doi/pdf/10.1145/3269206.3272006">pdf</a>    
  </ul>   

  <h4> Information theory </h4>
  <ul> 
  <li> Extreme Bandits using Robust Statistics, <i> IEEE Transactions on Information Theory, 2022 (early access). </i> <a href="https://arxiv.org/pdf/2109.04433.pdf">pdf</a>    
  <li> The benefits of diversity: Permutation recovery in unlabeled sensing from multiple measurement vectors, <i> IEEE Transactions on Information Theory, 2022. </i> <a href="https://arxiv.org/pdf/1909.02496.pdf">pdf</a>
  <li> Stability and Risk Bounds of Iterative Hard Thresholding, <i> IEEE Transactions on Information Theory, 2022. </i> <a href="https://arxiv.org/pdf/2203.09413.pdf">pdf</a>      
  </ul>   
  
  <h4> Privacy </h4>
  <ul> 
  <li> k-Median Clustering via Metric Embedding: Towards Better Initialization with Differential Privacy. <a href="https://arxiv.org/pdf/2206.12895.pdf">pdf</a>    
  <li> Breaking the Linear Error Barrier in Differentially Private Graph Distance Release, <i> NeurIPS 2022. </i> <a href="https://arxiv.org/pdf/2204.14247.pdf">pdf</a>    
  <li> NL2GDPR: Automatically Develop GDPR Compliant Android Application Features from Natural Language, <i> IEEE CNS 2022. </i> <a href="./publication/NL2App2022.pdf">pdf</a>    
  <li> Distances Release with Differential Privacy in Tree and Grid Graph, <i> ISIT 2022. </i> <a href="https://arxiv.org/pdf/2204.12488.pdf">pdf</a>
  </ul> 

  <h4> AI model security </h4>
  <ul>     
  <li> Defending Backdoor Attacks on Vision Transformer via Patch Processing. <a href="https://arxiv.org/pdf/2206.12381.pdf">pdf</a>
  <li> Marksman Backdoor: Backdoor Attacks with Arbitrary Target Class, <i> NeurIPS 2022.</i> <a href="https://arxiv.org/pdf/2210.09194.pdf">pdf</a>    
  <li> Integrity Authentication in Tree Models, <i> KDD 2022.</i> <a href="https://arxiv.org/pdf/2205.15444.pdf">pdf</a>            
  <li> Identification for Deep Neural Network: Simply Adjusting Few Weights!, <i> ICDE 2022.</i> <a href="https://ieeexplore.ieee.org/document/9835648">pdf</a>        
  <li> DeepAuth: A DNN Authentication Framework by Model-Unique and Fragile Signature Embedding, <i> AAAI 2022.</i> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/21193/20942">pdf</a>
  <li> Backdoor Attack with Imperceptible Input and Latent Modification, <i> NeurIPS 2021.</i> <a href="https://proceedings.neurips.cc/paper/2021/file/9d99197e2ebf03fc388d09f1e94af89b-Paper.pdf">pdf</a>    
  <li> LIRA: Learnable, Imperceptible and Robust Backdoor Attacks, <i> ICCV 2021.</i> <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Doan_LIRA_Learnable_Imperceptible_and_Robust_Backdoor_Attacks_ICCV_2021_paper.pdf">pdf</a>    
  <li> Robust Watermarking for Deep Neural Networks via Bi-level Optimization, <i> ICCV 2021.</i> <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Yang_Robust_Watermarking_for_Deep_Neural_Networks_via_Bi-Level_Optimization_ICCV_2021_paper.pdf">pdf</a>    

  </ul> 
    
  <h4> A/B testing </h4>
  <ul> 
  <li> A New and Unified Family of Covariate Adaptive Randomization Procedures and Their Properties, <i> JASA 2022. </i> <a href="./publication/JASA2022MaW.pdf">pdf</a>    
  <li> Adaptive A/B Test on Networks with Cluster Structures, <i> AISTATS 2022. </i> <a href="https://proceedings.mlr.press/v151/liu22g/liu22g.pdf">pdf</a>
  <li> Adaptive Randomization in Network Data. <a href="https://arxiv.org/pdf/2009.01273.pdf">pdf</a>      
  </ul>   
  
  <h4> Knowledge graphs (KG) </h4>
  <ul> 
  <li> OIE@OIA: an Adaptable and Efficient Open Information Extraction Framework, <i> ACL 2022. </i> <a href="https://aclanthology.org/2022.acl-long.430.pdf">pdf</a>
  <li> SpaceE: Knowledge Graph Embedding by Relational Linear Transformation in the Entity Space, <i> HT 2022. </i> <a href="https://arxiv.org/pdf/2204.10245.pdf">pdf</a>    
  <li> Explainable Concept Graph Completion by Bridging Open-DomainRelations and Concepts, <i> SDM 2022. </i> <a href="https://epubs.siam.org/doi/epdf/10.1137/1.9781611977172.76">pdf</a>    
  <li> MQuadE: a Unified Model for Knowledge Fact Embedding, <i> WWW 2021. </i> <a href="https://dl.acm.org/doi/10.1145/3442381.3449879">pdf</a>     
  <li> Extracting Knowledge from Web Text with Monte Carlo Tree Search, <i> WWW 2020. </i> <a href="https://dl.acm.org/doi/10.1145/3366423.3380010">pdf</a>     
  <li> A Predicate-Function-Argument Annotation of Natural Language for Open-Domain Information eXpression, <i> EMNLP 2020. </i> <a href="https://aclanthology.org/2020.emnlp-main.167.pdf">pdf</a>     
  <li> Learning Interpretable Relationships between Entities, Relations and Concepts via Bayesian Structure Learning on Open Domain Facts, <i> ACL 2020. </i> <a href="https://aclanthology.org/2020.acl-main.717.pdf">pdf</a>     
  <li> Integration of Knowledge Graph Embedding into Topic Modeling with Hierarchical Dirichlet Process, <i> NAACL 2019. </i> <a href="https://aclanthology.org/N19-1099.pdf">pdf</a>     
  <li> Knowledge Graph Embedding Based Question Answering, <i> WSDM 2019. </i> <a href="http://research.baidu.com/Public/uploads/5c1c9a58317b3.pdf">pdf</a>     
  <li> Logician and Orator: Learning from the Duality between Language and Knowledge in Open Domain, <i> EMNLP 2018. </i> <a href="https://aclanthology.org/D18-1236.pdf">pdf</a>     
  <li> Logician: A Unified End-to-End Neural Approach for Open-Domain Information Extraction, <i> WSDM 2018. </i> <a href="https://arxiv.org/pdf/1904.12535.pdf">pdf</a>     
  </ul> 

  <h4> Embedding based retrieval (EBR) with graph-based approxinate near neighbor (ANN) search</h4>
  <ul> 
  <li> Proximity Graph Maintenance for Fast Online Nearest Neighbor Search. <a href="https://arxiv.org/pdf/2206.10839.pdf">pdf</a>
  <li> Constrained Approximate Similarity Search on Proximity Graph. <a href="./publication/ConstrainedANN2022ZhaoW.pdf">pdf</a>    
  <li> Fast Neural Ranking on Bipartite Graph Indices, <i> VLDB 2022. </i> <a href="https://www.vldb.org/pvldb/vol15/p794-tan.pdf">pdf</a>      
  <li> Norm Adjusted Proximity Graph for Fast Inner Product Retrieval, <i> KDD 2021. </i> <a href="https://dl.acm.org/doi/10.1145/3447548.3467412">pdf</a>      
  <li> SONG: Approximate Nearest Neighbor Search on GPU, <i> ICDE 2020. </i> <a href="http://research.baidu.com/Public/uploads/5f5c37aa9c37c.pdf">pdf</a>      
  <li> Fast Item Ranking under Neural Network based Measures, <i> WSDM 2020. </i> <a href="http://research.baidu.com/Public/uploads/5e88947b04a4e.pdf">pdf</a>      
  <li> On Efficient Retrieval of Top Similarity Vectors, <i> EMNLP 2019. </i> <a href="https://aclanthology.org/D19-1527.pdf">pdf</a>      
  <li> Möbius Transformation for Fast Inner Product Search on Graph, <i> NeurIPS 2019. </i> <a href="https://proceedings.neurips.cc/paper/2019/file/0fd7e4f42a8b4b4ef33394d35212b13e-Paper.pdf">pdf</a>      
  </ul>   
    
    
  <h4> Embedding based retrieval (EBR), compression, and large-scale learning, with hashing methods</h4>
  <ul> 
  <li> GCWSNet: Generalized Consistent Weighted Sampling for Scalable and Accurate Training of Neural Networks. <a href="https://arxiv.org/pdf/2201.02283.pdf">pdf</a>    
  <li> C-MinHash: Improving Minwise Hashing with Circulant Permutation, <i> ICML 2022. </i> <a href="https://proceedings.mlr.press/v162/li22m/li22m.pdf">pdf</a>
  <li> Quantization Algorithms for Random Fourier Features, <i> ICML 2021. </i> <a href="http://proceedings.mlr.press/v139/li21i/li21i.pdf">pdf</a>      
  <li> Consistent Sampling Through Extremal Process, <i> WWW 2021. </i> <a href="https://dl.acm.org/doi/10.1145/3442381.3449955">pdf</a>      
  <li> Random Projections with Asymmetric Quantization, <i> NeurIPS 2019. </i> <a href="https://proceedings.neurips.cc/paper/2019/file/a32d7eeaae19821fd9ce317f3ce952a7-Paper.pdf">pdf</a>      
  <li> Re-randomized Densification for One Permutation Hashing and Bin-wise Consistent Weighted Sampling, <i> NeurIPS 2019. </i> <a href="https://proceedings.neurips.cc/paper/2019/file/9f067d8d6df2d4b8c64fb4c084d6c208-Paper.pdf">pdf</a>      
  <li> Sign-Full Random Projections, <i> AAAI 2019. </i> <a href="https://arxiv.org/pdf/1805.00533.pdf">pdf</a>      
  <li> On the Trade-Off Between Bit Depth and Number of Samples for a Basic Approach to Structured Signal Recovery From b -Bit Quantized Linear Measurements, <i> IEEE Transactions on Information Theory, 2018. </i> <a href="https://ieeexplore.ieee.org/document/8344517">pdf</a>        
  <li> Linearized GMM Kernels and Normalized Random Fourier Features, <i> KDD 2017. </i> <a href="https://dl.acm.org/doi/pdf/10.1145/3097983.3098081">pdf</a>      
  <li> Quantized Random Projections and Non-Linear Estimation of Cosine Similarity, <i> NIPS 2016. </i> <a href="https://proceedings.neurips.cc/paper/2016/file/186a157b2992e7daed3677ce8e9fe40f-Paper.pdf">pdf</a>      
  <li> Asymmetric Minwise Hashing for Indexing Binary Inner Products and Set Containment, <i> WWW 2015. </i> <a href="https://www.cs.cornell.edu/~anshu/papers/WWW2015.pdf">pdf</a>     
  <li> 0-Bit Consistent Weighted Samplings, <i> KDD 2015. </i> <a href="https://dl.acm.org/doi/10.1145/2783258.2783406">pdf</a>     
  <li> Densifying One Permutation Hashing via Rotation for Fast Near Neighbor Search, <i> ICML 2014. </i> <a href="http://proceedings.mlr.press/v32/shrivastava14.pdf">pdf</a>        
  <li> Coding for Random Projections, <i> ICML 2014. </i> <a href="http://proceedings.mlr.press/v32/lie14.pdf">pdf</a>        
  <li> In Defense of MinHash Over SimHash, <i> AISTATS 2014. </i> <a href="http://proceedings.mlr.press/v33/shrivastava14.pdf">pdf</a>         
  <li> Asymmetric LSH (ALSH) for Sublinear Time Maximum Inner Product Search (MIPS), <i> NIPS 2014. </i> <a href="https://proceedings.neurips.cc/paper/2014/file/310ce61c90f3a46e340ee8257bc70e93-Paper.pdf">pdf</a>      
  <li> Sign Cauchy Projections and Chi-Square Kernel, <i> NIPS 2013. </i> <a href="https://proceedings.neurips.cc/paper/2013/file/3210ddbeaa16948a702b6049b8d9a202-Paper.pdf">pdf</a>      
  <li> Beyond Pairwise: Provably Fast Algorithms for Approximate k-Way Similarity Search, <i> NIPS 2013. </i> <a href=https://proceedings.neurips.cc/paper/2013/file/f1b6f2857fb6d44dd73c7041e0aa0f19-Paper.pdf">pdf</a>      
  <li> One Permutation Hashing, <i> NIPS 2012. </i> <a href="https://proceedings.neurips.cc/paper/2012/file/eaa32c96f620053cf442ad32258076b9-Paper.pdf">pdf</a>      
  <li> Hashing Algorithms for Large-Scale Learning, <i> NIPS 2011. </i> <a href="https://proceedings.neurips.cc/paper/2011/file/0a1bf96b7165e962e90cb14648c9462d-Paper.pdf">pdf</a>      
  <li> Theory and Applications of b-Bit Minwise Hashing, <i> Communications of the ACM (CACM) 2011. </i> <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/CACM_hashing.pdf">pdf</a>      
  <li> b-Bit Minwise Hashing for Estimating Three-Way Similarities, <i> NIPS 2010. </i> <a href="https://proceedings.neurips.cc/paper/2010/file/208e43f0e45c4c78cafadb83d2888cb6-Paper.pdf">pdf</a>         
  <li> Approximating Higher-Order Distances Using Random Projections, <i> UAI 2010. </i> <a href="https://event.cwi.nl/uai2010/papers/UAI2010_0262.pdf">pdf</a>         
  <li> One Sketch For All: Theory and Application of Conditional Random Sampling, <i> NIPS 2008. </i> <a href="https://proceedings.neurips.cc/paper/2008/file/fe7ee8fc1959cc7214fa21c4840dff0a-Paper.pdf">pdf</a>      
  <li> Very sparse stable random projections for dimension reduction in Lα (0 <α ≤ 2) norm, <i> KDD 2007. </i> <a href="https://dl.acm.org/doi/10.1145/1281192.1281241">pdf</a>      
  <li> A Sketch Algorithm for Estimating Two-Way and Multi-Way Associations, <i> Computational Linguistics 2007. </i> <a href="https://direct.mit.edu/coli/article/33/3/305/1955/A-Sketch-Algorithm-for-Estimating-Two-Way-and">pdf</a>      
  <li> Very Sparse Random Projections, <i> KDD 2006. </i> <a href="https://hastie.su.domains/Papers/Ping/KDD06_rp.pdf">pdf</a>      
  <li> Conditional Random Sampling: A Sketch-based Sampling Technique for Sparse Data, <i> NIPS 2006. </i> <a href="https://proceedings.neurips.cc/paper/2006/file/aa6b7ad9d68bf3443c35d23de844463b-Paper.pdf">pdf</a>      
  <li> Using Sketches to Estimate Associations, <i> EMNLP 2005. </i> <a href="https://aclanthology.org/H05-1089.pdf">pdf</a>      
  </ul>       

  <h4> Deep learning algorithms, federated learning, distributed computing, adaptive training</h4>
  <ul> 
  <li> On Distributed Adaptive Optimization with Gradient Compression, <i> ICLR 2022. </i> <a href="https://openreview.net/pdf?id=CI-xXX9dg9l">pdf</a>    
  <li> A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model, <i> ICLR 2022. </i> <a href="https://openreview.net/pdf?id=31d5RLCUuXC">pdf</a>  
  <li> On the Convergence of Decentralized Adaptive Gradient Methods, <i> ACML 2022. </i> <a href="https://arxiv.org/pdf/2109.03194.pdf">pdf</a>      
  <li> Learning Energy-Based Generative Models via Coarse-to-Fine Expanding and Sampling, <i> ICLR 2021. </i> <a href="https://openreview.net/pdf?id=aD1_5zowqV">pdf</a>      
  <li> An Optimistic Acceleration of AMSGrad for Nonconvex Optimization, <i> ACML 2021. </i> <a href="https://proceedings.mlr.press/v157/wang21c/wang21c.pdf">pdf</a>      
  <li> Toward Communication Efficient Adaptive Gradient Method, <i> FODS 2020. </i> <a href="https://arxiv.org/pdf/2109.05109.pdf">pdf</a>      
  <li> Understanding and Detecting Convergence for Stochastic Gradient Descent with Momentum, <i> BIGDATA 2020. </i> <a href="https://arxiv.org/pdf/2008.12224.pdf">pdf</a>      
  <li> On Convergence of Distributed Approximate Newton Methods: Globalization, Sharper Bounds and Beyond, <i> Journal of Machine Learning Research 2020. </i> <a href="https://jmlr.org/papers/volume21/19-764/19-764.pdf">pdf</a>      
  <li> Towards Better Generalization of Adaptive Gradient Methods, <i> NeurIPS 2020. </i> <a href="https://proceedings.neurips.cc/paper/2020/file/08fb104b0f2f838f3ce2d2b3741a12c2-Paper.pdf">pdf</a>      
  <li> On Random Deep Weight-Tied Autoencoders: Exact Asymptotic Analysis, Phase Transitions, and Implications to Training, <i> ICLR 2019. </i> <a href="https://openreview.net/pdf?id=HJx54i05tX">pdf</a>      
  </ul>   

   
  <p></p><hr>


  
<!-- Default Statcounter code for pltrees.github.io
https://pltrees.github.io/ -->
<script type="text/javascript">
var sc_project=12821764; 
var sc_invisible=1; 
var sc_security="6492a57f"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="web stats"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/12821764/0/6492a57f/1/"
alt="web stats"
referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
<!-- End of Statcounter Code -->
  
</body>

</html>
