
<html>

<head>
<title>Ping Li</title>
<meta name="author" content="Ping Li">
<meta name="description" content="Personal Homepage">
<meta name="keywords" content="Artificial Intelligence, Machine Learning, Approximate Near Neighor Search, Multi-Armed Bandit, Advertising, Recommendation, Natural Language Processing, Research, Rutgers, Microsoft, LinkedIn">
<meta name="classification" content="Personal Homepage">
</head>

<body bgcolor="f7f7f7" text="black" link="blue" vlink="purple" alink="red">

<h1> <img src="./pic/PingLiPhoto2022.jpeg" width="100"> &nbsp;&nbsp;&nbsp; Ping Li &nbsp;&nbsp;(<img src="./pic/kids2018.jpeg" width="50">   <font size="-2">Alexander, Anderson, Arthur, Adeline</font>)</h1>

Distinguished Engineer, LinkedIn Ads. &nbsp;&nbsp;  <a href="https://www.linkedin.com/in/ping-li-a4624389/">LinkedIn Profile</a><br/><br/>
<a href="mailto:pingli98@gmail.com">pingli98@gmail.com</a> <br/>
700 Bellevue Way NE, Bellevue, WA 98004, USA<br/>
<p>

<p/><hr>

<h2> Activities</h2>

<ul>
  <b>
  </b>
  <li>[2022/11] Talk at Stanford on Towards a unified view of trees, neural nets, and kernels at LinkedIn. <a href="./publication/Stanford20221111.pdf">link</a>  
  <li>[2022/09] Talk at LinkedIn on embedding based retrieval (EBR) and approximate near neighbor (ANN) search. <a href="https://www.linkedin.com/feed/update/urn:li:activity:6972533869245865984/">link</a>
  <li>[2022/08] Talk at Google on boosting and trees <a href="https://www.linkedin.com/feed/update/urn:li:activity:6965026431579951104/">link</a> 

</ul>

<p></p><hr>
  
<h2>Publications</h2>

  
  <h4> Advertising (Baidu Ads) </h4>
  <ul>
  <li> Media report: A Look at Baidu’s Industrial-Scale GPU Training Architecture. <a href="https://www.nextplatform.com/2021/06/25/a-look-at-baidus-industrial-scale-gpu-training-architecture/">link</a>
  <li> Communication-Efficient TeraByte-Scale Model Training Framework for Online Advertising. <a href="https://arxiv.org/pdf/2201.05500.pdf">pdf</a>    
  <li> EGM: Enhanced Graph-based Model for Large-scale Video Advertisement Search, <i> KDD 2022. </i> <a href="https://dl.acm.org/doi/pdf/10.1145/3534678.3539061">pdf</a>        
  <li> Multi-scale Multi-modal Dictionary BERT For Effective Text-image Retrieval in Multimedia Advertising, <i> CIKM 2022.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3511808.3557653">pdf</a>    
  <li> Agile and Accurate CTR Prediction Model Training for Massive-Scale Online Advertising Systems, <i> SIGMOD 2021. </i> <a href="https://dl.acm.org/doi/pdf/10.1145/3448016.3457236">pdf</a>      
  <li> GemNN: Gating-Enhanced Multi-Task Neural Networks with Feature Interaction Learning for CTR Prediction, <i> SIGIR 2021.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3404835.3463116">pdf</a>  
  <li> Heterogeneous Attention Network for Effective and Efficient Cross-modal Retrieval, <i> SIGIR 2021.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3404835.3462924">pdf</a>
  <li> TIRA in Baidu Image Advertising, <i> ICDE 2021.</i> <a href="https://ieeexplore.ieee.org/document/9458762">pdf</a>
  <li> Efficient Learning to Learn a Robust CTR Model for Web-scale Online Sponsored Search Advertising, <i> CIKM 2021.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3459637.3481912">pdf</a>
  <li> Multi-modal Dictionary BERT for Cross-modal Video Search in Baidu Advertising, <i> CIKM 2021.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3459637.3481937">pdf</a>
  <li> MixBERT for Multi-modal Matching in Image Advertising, <i> CIKM 2021.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3459637.3482143">pdf</a>
  <li> Assorted Attention Network for Cross-Lingual Language-to-Vision Retrieval, <i> CIKM 2021.</i> <a href="https://dl.acm.org/doi/10.1145/3459637.3482233">pdf</a>
  <li> Combo-Attention Network for Baidu Video Advertising, <i> KDD 2020.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3394486.3403297">pdf</a>             
  <li> Video Recommendation with Multi-gate Mixture of Experts Soft Actor Critic, <i> SIGIR 2020.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3397271.3401238">pdf</a>              
  <li> Distributed Hierarchical GPU Parameter Server for Massive Scale Deep Learning Ads Systems, <i> MLSys 2020.</i> <a href="https://arxiv.org/pdf/2003.05622.pdf">pdf</a>           
  <li> Sample Optimization For Display Advertising, <i> CIKM 2020.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3340531.3412162">pdf</a>
  <li> AIBox: CTR Prediction Model Training on a Single Node, <i> CIKM 2019.</i> <a href="https://dl.acm.org/doi/pdf/10.1145/3357384.3358045">pdf</a>             
  <li> MOBIUS: Towards the Next Generation of Query-Ad Matching in Baidu’s Sponsored Search, <i> KDD 2019.</i> <a href="http://research.baidu.com/Public/uploads/5d12eca098d40.pdf">pdf</a>         
  </ul>

  <h4> Input Method Editor (Baidu IME) </h4>
  <ul> 
  <li> Improved Touch-screen Inputting Using Sequence-level Prediction Generation, <i> WWW 2020. </i> <a href="https://dl.acm.org/doi/pdf/10.1145/3366423.3380080">pdf</a>    
  <li> FastInput: Improving Input Efficiency on Mobile Devices, <i> CIKM 2018. </i> <a href="https://dl.acm.org/doi/pdf/10.1145/3269206.3272006">pdf</a>    
  </ul>   

  <h4> Information Theory </h4>
  <ul> 
  <li> Extreme Bandits using Robust Statistics, <i> IEEE Transactions on Information Theory, 2022 (early access). </i> <a href="https://arxiv.org/pdf/2109.04433.pdf">pdf</a>    
  <li> The benefits of diversity: Permutation recovery in unlabeled sensing from multiple measurement vectors, <i> IEEE Transactions on Information Theory, 2022. </i> <a href="https://arxiv.org/pdf/1909.02496.pdf">pdf</a>
  <li> Stability and Risk Bounds of Iterative Hard Thresholding, <i> IEEE Transactions on Information Theory, 2022. </i> <a href="https://arxiv.org/pdf/2203.09413.pdf">pdf</a>      
  </ul>   
  
  <h4> Privacy </h4>
  <ul> 
  <li> k-Median Clustering via Metric Embedding: Towards Better Initialization with Differential Privacy. <a href="https://arxiv.org/pdf/2206.12895.pdf">pdf</a>    
  <li> Breaking the Linear Error Barrier in Differentially Private Graph Distance Release, <i> NeurIPS 2022. </i> <a href="https://arxiv.org/pdf/2204.14247.pdf">pdf</a>    
  <li> NL2GDPR: Automatically Develop GDPR Compliant Android Application Features from Natural Language, <i> IEEE CNS 2022. </i> <a href="https://arxiv.org/pdf/2208.13361.pdf">pdf</a>    
  <li> Distances Release with Differential Privacy in Tree and Grid Graph, <i> ISIT 2022. </i> <a href="https://arxiv.org/pdf/2204.12488.pdf">pdf</a>
  </ul> 

  <h4> AI Model Security </h4>
  <ul>     
  <li> Defending Backdoor Attacks on Vision Transformer via Patch Processing.<i> AAAI 2023.</i> <a href="https://arxiv.org/pdf/2206.12381.pdf">pdf</a>
  <li> Marksman Backdoor: Backdoor Attacks with Arbitrary Target Class, <i> NeurIPS 2022.</i> <a href="https://arxiv.org/pdf/2206.12381.pdf">pdf</a>    
  <li> Integrity Authentication in Tree Models, <i> KDD 2022.</i> <a href="https://arxiv.org/pdf/2205.15444.pdf">pdf</a>            
  <li> Identification for Deep Neural Network: Simply Adjusting Few Weights!, <i> ICDE 2022.</i> <a href="https://ieeexplore.ieee.org/document/9835648">pdf</a>        
  <li> DeepAuth: A DNN Authentication Framework by Model-Unique and Fragile Signature Embedding, <i> AAAI 2022.</i> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/21193/20942">pdf</a>
  <li> Backdoor Attack with Imperceptible Input and Latent Modification, <i> NeurIPS 2021.</i> <a href="https://proceedings.neurips.cc/paper/2021/file/9d99197e2ebf03fc388d09f1e94af89b-Paper.pdf">pdf</a>    
  <li> LIRA: Learnable, Imperceptible and Robust Backdoor Attacks, <i> ICCV 2021.</i> <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Doan_LIRA_Learnable_Imperceptible_and_Robust_Backdoor_Attacks_ICCV_2021_paper.pdf">pdf</a>    
  <li> Robust Watermarking for Deep Neural Networks via Bi-level Optimization, <i> ICCV 2021.</i> <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Yang_Robust_Watermarking_for_Deep_Neural_Networks_via_Bi-Level_Optimization_ICCV_2021_paper.pdf">pdf</a>    

  </ul> 
    
  <h4> A/B Testing </h4>
  <ul> 
  <li> A New and Unified Family of Covariate Adaptive Randomization Procedures and Their Properties, <i> JASA 2022. </i> <a href="./publication/JASA2022MaW.pdf">pdf</a>    
  <li> Adaptive A/B Test on Networks with Cluster Structures, <i> AISTATS 2022. </i> <a href="https://proceedings.mlr.press/v151/liu22g/liu22g.pdf">pdf</a>
  <li> Adaptive Randomization in Network Data. <a href="https://arxiv.org/pdf/2009.01273.pdf">pdf</a>      
  </ul>   
  
  <h4> Knowledge graphs (KG) </h4>
  <ul> 
  <li> OIE@OIA: an Adaptable and Efficient Open Information Extraction Framework, <i> ACL 2022. </i> <a href="https://aclanthology.org/2022.acl-long.430.pdf">pdf</a>
  <li> SpaceE: Knowledge Graph Embedding by Relational Linear Transformation in the Entity Space, <i> HT 2022. </i> <a href="https://arxiv.org/pdf/2204.10245.pdf">pdf</a>    
  <li> MQuadE: a Unified Model for Knowledge Fact Embedding, <i> WWW 2021. </i> <a href="https://dl.acm.org/doi/10.1145/3442381.3449879">pdf</a>     
  <li> Extracting Knowledge from Web Text with Monte Carlo Tree Search, <i> WWW 2020. </i> <a href="https://dl.acm.org/doi/10.1145/3366423.3380010">pdf</a>     
  <li> An Advantage Actor-Critic Algorithm with Confidence Exploration forOpen Information Extraction, <i> SDM 2020. </i> <a href="https://epubs.siam.org/doi/epdf/10.1137/1.9781611976236.25">pdf</a>     
  <li> A Predicate-Function-Argument Annotation of Natural Language for Open-Domain Information eXpression, <i> EMNLP 2020. </i> <a href="https://aclanthology.org/2020.emnlp-main.167.pdf">pdf</a>     
  <li> Learning Interpretable Relationships between Entities, Relations and Concepts via Bayesian Structure Learning on Open Domain Facts, <i> ACL 2020. </i> <a href="https://aclanthology.org/2020.acl-main.717.pdf">pdf</a>     
  <li> Integration of Knowledge Graph Embedding into Topic Modeling with Hierarchical Dirichlet Process, <i> NAACL 2019. </i> <a href="https://aclanthology.org/N19-1099.pdf">pdf</a>     
  <li> Knowledge Graph Embedding Based Question Answering, <i> WSDM 2019. </i> <a href="http://research.baidu.com/Public/uploads/5c1c9a58317b3.pdf">pdf</a>     
  <li> Logician and Orator: Learning from the Duality between Language and Knowledge in Open Domain, <i> EMNLP 2018. </i> <a href="https://aclanthology.org/D18-1236.pdf">pdf</a>     
  <li> Logician: A Unified End-to-End Neural Approach for Open-Domain Information Extraction, <i> WSDM 2018. </i> <a href="https://arxiv.org/pdf/1904.12535.pdf">pdf</a>     
  </ul> 

  <h4> Embedding based retrieval (EBR), graph-based approxinate near neighbor (ANN) search</h4>
  <ul> 
  <li> Proximity Graph Maintenance for Fast Online Nearest Neighbor Search. <a href="https://arxiv.org/pdf/2206.10839.pdf">pdf</a>
  <li> Constrained Approximate Similarity Search on Proximity Graph. <a href="./publication/ConstrainedANN2022ZhaoW.pdf">pdf</a>    
  <li> Fast Neural Ranking on Bipartite Graph Indices, <i> VLDB 2022. </i> <a href="https://www.vldb.org/pvldb/vol15/p794-tan.pdf">pdf</a>      
  <li> Norm Adjusted Proximity Graph for Fast Inner Product Retrieval, <i> KDD 2021. </i> <a href="https://dl.acm.org/doi/10.1145/3447548.3467412">pdf</a>      
  <li> SONG: Approximate Nearest Neighbor Search on GPU, <i> ICDE 2020. </i> <a href="http://research.baidu.com/Public/uploads/5f5c37aa9c37c.pdf">pdf</a>      
  <li> Fast Item Ranking under Neural Network based Measures, <i> WSDM 2020. </i> <a href="http://research.baidu.com/Public/uploads/5e88947b04a4e.pdf">pdf</a>      
  <li> On Efficient Retrieval of Top Similarity Vectors, <i> EMNLP 2019. </i> <a href="https://aclanthology.org/D19-1527.pdf">pdf</a>      
  <li> Möbius Transformation for Fast Inner Product Search on Graph, <i> NeurIPS 2019. </i> <a href="https://proceedings.neurips.cc/paper/2019/file/0fd7e4f42a8b4b4ef33394d35212b13e-Paper.pdf">pdf</a>      
  </ul>   
    
    
  <h4> Hashing methods for data compression, approximate near neighbor search, and large-scale machine learning</h4>
  <ul> 
  <li> GCWSNet: Generalized Consistent Weighted Sampling for Scalable and Accurate Training of Neural Networks. <a href="https://arxiv.org/pdf/2201.02283.pdf">pdf</a>    
  <li> C-MinHash: Improving Minwise Hashing with Circulant Permutation, <i> ICML 2022. </i> <a href="https://proceedings.mlr.press/v162/li22m/li22m.pdf">pdf</a>
  <li> Quantization Algorithms for Random Fourier Features, <i> ICML 2021. </i> <a href="http://proceedings.mlr.press/v139/li21i/li21i.pdf">pdf</a>      
  <li> Consistent Sampling Through Extremal Process, <i> WWW 2021. </i> <a href="https://dl.acm.org/doi/10.1145/3442381.3449955">pdf</a>      
  <li> Random Projections with Asymmetric Quantization, <i> NeurIPS 2019. </i> <a href="https://proceedings.neurips.cc/paper/2019/file/a32d7eeaae19821fd9ce317f3ce952a7-Paper.pdf">pdf</a>      
  <li> Re-randomized Densification for One Permutation Hashing and Bin-wise Consistent Weighted Sampling, <i> NeurIPS 2019. </i> <a href="https://proceedings.neurips.cc/paper/2019/file/9f067d8d6df2d4b8c64fb4c084d6c208-Paper.pdf">pdf</a>      
  <li> Sign-Full Random Projections, <i> AAAI 2019. </i> <a href="https://arxiv.org/pdf/1805.00533.pdf">pdf</a>      
  <li> On the Trade-Off Between Bit Depth and Number of Samples for a Basic Approach to Structured Signal Recovery From b -Bit Quantized Linear Measurements, <i> IEEE Transactions on Information Theory, 2018. </i> <a href="https://ieeexplore.ieee.org/document/8344517">pdf</a>        
  <li> Linearized GMM Kernels and Normalized Random Fourier Features, <i> KDD 2017. </i> <a href="https://dl.acm.org/doi/pdf/10.1145/3097983.3098081">pdf</a>      
  <li> Quantized Random Projections and Non-Linear Estimation of Cosine Similarity, <i> NIPS 2016. </i> <a href="https://proceedings.neurips.cc/paper/2016/file/186a157b2992e7daed3677ce8e9fe40f-Paper.pdf">pdf</a>      
  <li> 0-Bit Consistent Weighted Samplings, <i> KDD 2015. </i> <a href="https://dl.acm.org/doi/10.1145/2783258.2783406">pdf</a>      
  <li> Asymmetric LSH (ALSH) for Sublinear Time Maximum Inner Product Search (MIPS), <i> NIPS 2014. </i> <a href="https://proceedings.neurips.cc/paper/2014/file/310ce61c90f3a46e340ee8257bc70e93-Paper.pdf">pdf</a>      
  <li> Sign Cauchy Projections and Chi-Square Kernel, <i> NIPS 2013. </i> <a href="https://proceedings.neurips.cc/paper/2013/file/3210ddbeaa16948a702b6049b8d9a202-Paper.pdf">pdf</a>      
  <li> One Permutation Hashing, <i> NIPS 2012. </i> <a href="https://proceedings.neurips.cc/paper/2012/file/eaa32c96f620053cf442ad32258076b9-Paper.pdf">pdf</a>      
  <li> Hashing Algorithms for Large-Scale Learning, <i> NIPS 2011. </i> <a href="https://proceedings.neurips.cc/paper/2011/file/0a1bf96b7165e962e90cb14648c9462d-Paper.pdf">pdf</a>      
  <li> Theory and Applications of b-Bit Minwise Hashing, <i> Communications of the ACM (CACM) 2011. </i> <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/CACM_hashing.pdf">pdf</a>      
  <li> One Sketch For All: Theory and Application of Conditional Random Sampling, <i> NIPS 2008. </i> <a href="https://proceedings.neurips.cc/paper/2008/file/fe7ee8fc1959cc7214fa21c4840dff0a-Paper.pdf">pdf</a>      
  <li> Very sparse stable random projections for dimension reduction in Lα (0 <α ≤ 2) norm, <i> KDD 2007. </i> <a href="https://dl.acm.org/doi/10.1145/1281192.1281241">pdf</a>      
  <li> A Sketch Algorithm for Estimating Two-Way and Multi-Way Associations, <i> Computational Linguistics 2007. </i> <a href="https://direct.mit.edu/coli/article/33/3/305/1955/A-Sketch-Algorithm-for-Estimating-Two-Way-and">pdf</a>      
  <li> Very Sparse Random Projections, <i> KDD 2006. </i> <a href="https://hastie.su.domains/Papers/Ping/KDD06_rp.pdf">pdf</a>      
  <li> Conditional Random Sampling: A Sketch-based Sampling Technique for Sparse Data, <i> NIPS 2006. </i> <a href="https://proceedings.neurips.cc/paper/2006/file/aa6b7ad9d68bf3443c35d23de844463b-Paper.pdf">pdf</a>      
  <li> Using Sketches to Estimate Associations, <i> EMNLP 2005. </i> <a href="https://aclanthology.org/H05-1089.pdf">pdf</a>      
  </ul>       

  <h4> Deep Learning algorithms, distributed computing, and federated learning</h4>
  <ul> 
  <li> On Distributed Adaptive Optimization with Gradient Compression, <i> ICLR 2022. </i> <a href="https://openreview.net/pdf?id=CI-xXX9dg9l">pdf</a>    
  <li> Optimal Transport for Long-Tailed Recognition with Learnable Cost Matrix, <i> ICLR 2022. </i> <a href="https://openreview.net/pdf?id=t98k9ePQQpn">pdf</a>    
  <li> A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model, <i> ICLR 2022. </i> <a href="https://openreview.net/pdf?id=31d5RLCUuXC">pdf</a>      
  <li> On the Convergence of Decentralized Adaptive Gradient Methods, <i> ACML 2022. </i> <a href="https://arxiv.org/pdf/2109.03194.pdf">pdf</a>      
  <li> Learning Energy-Based Generative Models via Coarse-to-Fine Expanding and Sampling, <i> ICLR 2021. </i> <a href="https://openreview.net/pdf?id=aD1_5zowqV">pdf</a>      
  <li> Toward Communication Efficient Adaptive Gradient Method, <i> FODS 2020. </i> <a href="https://arxiv.org/pdf/2109.05109.pdf">pdf</a>      
  <li> Towards Better Generalization of Adaptive Gradient Methods, <i> NeurIPS 2020. </i> <a href="https://proceedings.neurips.cc/paper/2020/file/08fb104b0f2f838f3ce2d2b3741a12c2-Paper.pdf">pdf</a>      
  <li> On Random Deep Weight-Tied Autoencoders: Exact Asymptotic Analysis, Phase Transitions, and Implications to Training, <i> ICLR 2019. </i> <a href="https://openreview.net/pdf?id=HJx54i05tX">pdf</a>      
  </ul>   
  
   
  <p></p><hr>


  
<script type="text/javascript" language="javascript">
var sc_project=1483954;
var sc_invisible=1;
var sc_partition=13;
var sc_security="8c85df56";
</script>

<script type="text/javascript" language="javascript" src="http://www.statcounter.com/counter/counter.js"></script><noscript><a
href="http://www.statcounter.com/" target="_blank"><img
src="http://c14.statcounter.com/counter.php?sc_project=1483954&amp;java=0&amp;security=8c85df56&amp;invisible=1" alt="simple hit counter"
border="0"></a> </noscript>

</body>

</html>
